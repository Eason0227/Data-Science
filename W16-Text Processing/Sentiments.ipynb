{"cells":[{"cell_type":"markdown","metadata":{"id":"shWnO3pMKYZ4"},"source":["### Sentiments Analysis ###\n","\n","Sentiment analysis also known as opinion mining refers to the automated task of determining the subjective 'tone' or mood  of a given natural language response or text. It aims to gauge the subjective judgments and feelings in the texts.\n","\n","In its simplest form it is a multiclass text classification text where the text is classified into positive, neutral, or negative sentiment. The number of classes can vary according to the nature of the task, for example it can include emotions like happy, angry and sad. \n","\n","\n","\n","#### Application of sentiment analysis\n","Sentiment analysis has applications in a wide variety of domains including analyzing user reviews, tweet sentiment, etc. Let‚Äôs go through some of them here:\n","\n","- Social media monitoring: analyzing trends and opinitions\n","- Movie reviews: Analysing online movie reviews and feedback to judge the quality of the movie, \n","- News sentiment analysis: analyzing trends and their sentiments \n","- Brand monitoring and market research: understanding what users are saying about a product\n","- medical uses: monitoring for depression in a person\n","\n","\n","#### Rule-based sentiment analysis\n","Rule-based sentiment analysis is one of the very basic approaches to calculate text sentiments. It only requires minimal pre-work and the idea is quite simple, this method does not use any machine learning to figure out the text sentiment. For example, we can figure out the sentiments of a sentence by counting the number of times the user has used the word ‚Äúsad‚Äù in his/her tweet. \n","\n","Now, let‚Äôs check out some python packages that work using this method.\n","\n","Install the following:\n","\n","- textblob\n","- vader: \n","- flair"]},{"cell_type":"markdown","metadata":{"id":"xGdS9ALBKYZ7"},"source":["### Textblob \n","It is a simple python library that offers API access to different NLP tasks such as sentiment analysis, spelling correction, etc.\n","\n","Textblob sentiment analyzer returns two properties for a given input sentence:polarity and subjectivity\n","\n","The sentiment property returns a namedtuple of the form Sentiment(polarity, subjectivity). The polarity score is a float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective. Subjective sentences generally refer to personal opinion, emotion, or judgment. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O-60EKs0KYZ8","executionInfo":{"status":"ok","timestamp":1641991305589,"user_tz":-480,"elapsed":4135,"user":{"displayName":"Ëî°ÊâøÂì≤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUjUENY9knqXHiDlNA8p9rKPZb-kSJuB4r-BTpIQ=s64","userId":"08856972309667959252"}},"outputId":"a2968a81-8902-4d98-a130-6841be990c3f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n","Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n"]}],"source":["!pip install textblob"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tXE2_M_EKYZ9","executionInfo":{"status":"ok","timestamp":1641991305589,"user_tz":-480,"elapsed":7,"user":{"displayName":"Ëî°ÊâøÂì≤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUjUENY9knqXHiDlNA8p9rKPZb-kSJuB4r-BTpIQ=s64","userId":"08856972309667959252"}},"outputId":"da2bf699-413a-435b-fed7-8b6d860809f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sentiment(polarity=0.8, subjectivity=0.95)\n"]}],"source":["from textblob import TextBlob\n","\n","testimonial = TextBlob(\"I am the amazing Textblob. Textblob is wonderful!\")\n","print(testimonial.sentiment)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vGELE2xzKYZ-","executionInfo":{"status":"ok","timestamp":1641991305590,"user_tz":-480,"elapsed":4,"user":{"displayName":"Ëî°ÊâøÂì≤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUjUENY9knqXHiDlNA8p9rKPZb-kSJuB4r-BTpIQ=s64","userId":"08856972309667959252"}},"outputId":"934f7b9a-caab-4dd0-e3fe-51eb5dd21e66"},"outputs":[{"output_type":"stream","name":"stdout","text":["I am very kind and good........................... Sentiment(polarity=0.74, subjectivity=0.8)\n","I am very angry................................... Sentiment(polarity=-0.65, subjectivity=1.0)\n"]}],"source":["sentences = [\"I am very kind and good\",\n","             \"I am very angry\",\n","             ]\n","for sentence in sentences:\n","    vs = TextBlob(sentence)\n","    print(\"{:.<50} {}\".format(sentence, str(vs.sentiment)))"]},{"cell_type":"markdown","metadata":{"id":"ETMw-hhTKYZ-"},"source":["### VADER\n","\n","VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. It is fully open-sourced under the [MIT License] \n","\n","VADER incorporate numerous lexical features common to sentiment expression in microblogs, including:\n","\n","- a full list of Western-style emoticons, for example, :-) denotes a smiley face and generally indicates positive sentiment\n","- sentiment-related acronyms and initialisms (e.g., LOL and WTF are both examples of sentiment-laden initialisms)\n","- commonly used slang with sentiment value (e.g., nah, meh and giggly).\n","\n","VADER incorporate word-order sensitive relationships between terms. For example, degree modifiers (also called intensifiers, booster words, or degree adverbs) impact sentiment intensity by either increasing or decreasing the intensity:\n","\n","- \"The service here is extremely good\"\n","- \"The service here is good\"\n","- \"The service here is marginally good\"\n","\n","A sentiment polarity (positive/negative), and the sentiment intensity on a scale from ‚Äì4 to +4 is used. For example, the word \"okay\" has a positive valence of 0.9, \"good\" is 1.9, and \"great\" is 3.1, whereas \"horrible\" is ‚Äì2.5, the frowning emoticon :( is ‚Äì2.2, and \"sucks\" and it's slang derivative \"sux\" are both ‚Äì1.5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XoS9Y4cwKYZ_","executionInfo":{"status":"ok","timestamp":1641991309472,"user_tz":-480,"elapsed":3885,"user":{"displayName":"Ëî°ÊâøÂì≤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUjUENY9knqXHiDlNA8p9rKPZb-kSJuB4r-BTpIQ=s64","userId":"08856972309667959252"}},"outputId":"001f5a6d-21f0-41a2-8cc0-80d0707c7861"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.7/dist-packages (3.3.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.27.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.0.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2021.10.8)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n"]}],"source":["!pip install vaderSentiment"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oMDhu06bKYaA","executionInfo":{"status":"ok","timestamp":1641991309472,"user_tz":-480,"elapsed":10,"user":{"displayName":"Ëî°ÊâøÂì≤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUjUENY9knqXHiDlNA8p9rKPZb-kSJuB4r-BTpIQ=s64","userId":"08856972309667959252"}},"outputId":"bd88467b-dde2-4ade-92cd-3751f9f5d618"},"outputs":[{"output_type":"stream","name":"stdout","text":["VADER is smart, handsome, and funny.............................. {'neg': 0.0, 'neu': 0.254, 'pos': 0.746, 'compound': 0.8316}\n","VADER is smart, handsome, and funny!............................. {'neg': 0.0, 'neu': 0.248, 'pos': 0.752, 'compound': 0.8439}\n","VADER is very smart, handsome, and funny......................... {'neg': 0.0, 'neu': 0.299, 'pos': 0.701, 'compound': 0.8545}\n","VADER is VERY SMART, handsome, and FUNNY......................... {'neg': 0.0, 'neu': 0.246, 'pos': 0.754, 'compound': 0.9227}\n","VADER is VERY SMART, handsome, and FUNNY!!!...................... {'neg': 0.0, 'neu': 0.233, 'pos': 0.767, 'compound': 0.9342}\n","VADER is VERY SMART, uber handsome, and FRIGGIN FUNNY!!!......... {'neg': 0.0, 'neu': 0.294, 'pos': 0.706, 'compound': 0.9469}\n","VADER is not smart, handsome, nor funny.......................... {'neg': 0.646, 'neu': 0.354, 'pos': 0.0, 'compound': -0.7424}\n","The book was good................................................ {'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n","At least it isn't a horrible book................................ {'neg': 0.0, 'neu': 0.678, 'pos': 0.322, 'compound': 0.431}\n","The book was only kind of good................................... {'neg': 0.0, 'neu': 0.697, 'pos': 0.303, 'compound': 0.3832}\n","The plot was good, but the characters are uncompelling and the dialog is not great. {'neg': 0.327, 'neu': 0.579, 'pos': 0.094, 'compound': -0.7042}\n","Today SUX!....................................................... {'neg': 0.779, 'neu': 0.221, 'pos': 0.0, 'compound': -0.5461}\n","Today only kinda sux! But I'll get by, lol....................... {'neg': 0.127, 'neu': 0.556, 'pos': 0.317, 'compound': 0.5249}\n","Make sure you :) or :D today!.................................... {'neg': 0.0, 'neu': 0.294, 'pos': 0.706, 'compound': 0.8633}\n","Catch utf-8 emoji such as such as üíò and üíã and üòÅ.................. {'neg': 0.0, 'neu': 0.615, 'pos': 0.385, 'compound': 0.875}\n","Not bad at all................................................... {'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'compound': 0.431}\n"]}],"source":["from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","    #note: depending on how you installed (e.g., using source code download versus pip install), you may need to import like this:\n","    #from vaderSentiment import SentimentIntensityAnalyzer\n","\n","# --- examples -------\n","sentences = [\"VADER is smart, handsome, and funny.\",  # positive sentence example\n","             \"VADER is smart, handsome, and funny!\",  # punctuation emphasis handled correctly (sentiment intensity adjusted)\n","             \"VADER is very smart, handsome, and funny.\", # booster words handled correctly (sentiment intensity adjusted)\n","             \"VADER is VERY SMART, handsome, and FUNNY.\",  # emphasis for ALLCAPS handled\n","             \"VADER is VERY SMART, handsome, and FUNNY!!!\", # combination of signals - VADER appropriately adjusts intensity\n","             \"VADER is VERY SMART, uber handsome, and FRIGGIN FUNNY!!!\", # booster words & punctuation make this close to ceiling for score\n","             \"VADER is not smart, handsome, nor funny.\",  # negation sentence example\n","             \"The book was good.\",  # positive sentence\n","             \"At least it isn't a horrible book.\",  # negated negative sentence with contraction\n","             \"The book was only kind of good.\", # qualified positive sentence is handled correctly (intensity adjusted)\n","             \"The plot was good, but the characters are uncompelling and the dialog is not great.\", # mixed negation sentence\n","             \"Today SUX!\",  # negative slang with capitalization emphasis\n","             \"Today only kinda sux! But I'll get by, lol\", # mixed sentiment example with slang and constrastive conjunction \"but\"\n","             \"Make sure you :) or :D today!\",  # emoticons handled\n","             \"Catch utf-8 emoji such as such as üíò and üíã and üòÅ\",  # emojis handled\n","             \"Not bad at all\"  # Capitalized negation\n","             ]\n","\n","analyzer = SentimentIntensityAnalyzer()\n","for sentence in sentences:\n","    vs = analyzer.polarity_scores(sentence)\n","    print(\"{:.<65} {}\".format(sentence, str(vs)))"]},{"cell_type":"code","source":["vs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oSPsYe0Qdpmy","executionInfo":{"status":"ok","timestamp":1641991309473,"user_tz":-480,"elapsed":9,"user":{"displayName":"Ëî°ÊâøÂì≤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUjUENY9knqXHiDlNA8p9rKPZb-kSJuB4r-BTpIQ=s64","userId":"08856972309667959252"}},"outputId":"a9d52f6d-4a8e-463a-f146-f2d4b442727f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'compound': 0.431, 'neg': 0.0, 'neu': 0.513, 'pos': 0.487}"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"opRxG75IKYaA"},"source":["### VADER Scoring\n","The compound score is computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive). This is the most useful metric if you want a single unidimensional measure of sentiment for a given sentence. Calling it a 'normalized, weighted composite score' is accurate.\n","\n","It is also useful for researchers who would like to set standardized thresholds for classifying sentences as either positive, neutral, or negative. Typical threshold values (used in the literature cited on this page) are:\n","\n","positive sentiment: compound score >= 0.05\n","neutral sentiment: (compound score > -0.05) and (compound score < 0.05)\n","negative sentiment: compound score <= -0.05\n","The pos, neu, and neg scores are ratios for proportions of text that fall in each category (so these should all add up to be 1... or close to it with float operation). These are the most useful metrics if you want multidimensional measures of sentiment for a given sentence."]},{"cell_type":"markdown","metadata":{"id":"MCW6a9DWKYaB"},"source":["### Flair \n","\n","Flair is a state-of-the-art natural language processing (NLP) models for text. It can perform named entity recognition (NER), part-of-speech tagging (PoS), sense disambiguation and classification and is supported with a rapidly growing number of languages.  Flair pretrained sentiment analysis model is trained on IMDB dataset but it can be trained on your own dataset. \n","\n","source: https://github.com/flairNLP/flair"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DwfZkdfxKYaB","executionInfo":{"status":"ok","timestamp":1642003271432,"user_tz":-480,"elapsed":50664,"user":{"displayName":"Ëî°ÊâøÂì≤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUjUENY9knqXHiDlNA8p9rKPZb-kSJuB4r-BTpIQ=s64","userId":"08856972309667959252"}},"outputId":"d0425f0b-8a15-49be-af56-d4189a3fc26f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting flair\n","  Downloading flair-0.10-py3-none-any.whl (322 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 322 kB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n","Collecting sentencepiece==0.1.95\n","  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.2 MB 38.3 MB/s \n","\u001b[?25hCollecting konoha<5.0.0,>=4.0.0\n","  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n","Collecting bpemb>=0.3.2\n","  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.2)\n","Collecting gdown==3.12.2\n","  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting ftfy\n","  Downloading ftfy-6.0.3.tar.gz (64 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 64 kB 2.6 MB/s \n","\u001b[?25hCollecting langdetect\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 981 kB 38.6 MB/s \n","\u001b[?25hRequirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n","Collecting mpld3==0.3\n","  Downloading mpld3-0.3.tar.gz (788 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 788 kB 39.6 MB/s \n","\u001b[?25hCollecting huggingface-hub\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67 kB 4.8 MB/s \n","\u001b[?25hCollecting segtok>=1.5.7\n","  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n","Collecting conllu>=4.0\n","  Downloading conllu-4.4.1-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n","Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.10.0+cu111)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n","Collecting janome\n","  Downloading Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19.7 MB 1.4 MB/s \n","\u001b[?25hCollecting wikipedia-api\n","  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n","Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.62.3)\n","Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n","Collecting transformers>=4.0.0\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.4 MB 37.4 MB/s \n","\u001b[?25hCollecting sqlitedict>=1.6.0\n","  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n","Collecting deprecated>=1.2.4\n","  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n","Collecting more-itertools~=8.8.0\n","  Downloading more_itertools-8.8.0-py3-none-any.whl (48 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48 kB 4.9 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (3.4.2)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (1.15.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (1.19.5)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.13.3)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (5.2.1)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (1.4.1)\n","Collecting importlib-metadata<4.0.0,>=3.7.0\n","  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n","Collecting requests\n","  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63 kB 1.7 MB/s \n","\u001b[?25hCollecting overrides<4.0.0,>=3.0.0\n","  Downloading overrides-3.1.0.tar.gz (11 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.7.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (3.0.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.0.10)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2021.10.8)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (3.0.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 596 kB 49.7 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.3)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.3 MB 43.7 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 895 kB 24.4 MB/s \n","\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n","Building wheels for collected packages: gdown, mpld3, overrides, sqlitedict, ftfy, langdetect, wikipedia-api\n","  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9704 sha256=9b1304d32bc821e64acd45bfd4b7d2bed040b2607ad57623810eeeba66189c5d\n","  Stored in directory: /root/.cache/pip/wheels/ba/e0/7e/726e872a53f7358b4b96a9975b04e98113b005cd8609a63abc\n","  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=d328d29114fd5bf71a549cafbff37946455bf863ca56fe505c54430f9eb2a5c2\n","  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=e5cb383e26a35024a2bfcbdcf744c6b18992825bcc4bcfc1f24fd42618ba29a2\n","  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n","  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14393 sha256=e5b268ce9813661dbdbffd580f1a1c631929045611afc5899b3ac6d80be2c491\n","  Stored in directory: /root/.cache/pip/wheels/af/94/06/18c0e83e9e227da8f3582810b51f319bbfd181e508676a56c8\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=9b231f762356484ad345b5b3bcc4eba04ad870fd9624187957a5e4bb76722541\n","  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=aebd6d9943df70f381595935986ef07d0a4a23ab93eaf1d3288222129ad2a7e0\n","  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n","  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13477 sha256=a718a974c3716ea97329359f58253588dc60bd95876d1ea464cea217a1ecb46a\n","  Stored in directory: /root/.cache/pip/wheels/d3/24/56/58ba93cf78be162451144e7a9889603f437976ef1ae7013d04\n","Successfully built gdown mpld3 overrides sqlitedict ftfy langdetect wikipedia-api\n","Installing collected packages: requests, pyyaml, importlib-metadata, tokenizers, sentencepiece, sacremoses, overrides, huggingface-hub, wikipedia-api, transformers, sqlitedict, segtok, mpld3, more-itertools, langdetect, konoha, janome, gdown, ftfy, deprecated, conllu, bpemb, flair\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 4.10.0\n","    Uninstalling importlib-metadata-4.10.0:\n","      Successfully uninstalled importlib-metadata-4.10.0\n","  Attempting uninstall: more-itertools\n","    Found existing installation: more-itertools 8.12.0\n","    Uninstalling more-itertools-8.12.0:\n","      Successfully uninstalled more-itertools-8.12.0\n","  Attempting uninstall: gdown\n","    Found existing installation: gdown 3.6.4\n","    Uninstalling gdown-3.6.4:\n","      Successfully uninstalled gdown-3.6.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed bpemb-0.3.3 conllu-4.4.1 deprecated-1.2.13 flair-0.10 ftfy-6.0.3 gdown-3.12.2 huggingface-hub-0.4.0 importlib-metadata-3.10.1 janome-0.4.1 konoha-4.6.5 langdetect-1.0.9 more-itertools-8.8.0 mpld3-0.3 overrides-3.1.0 pyyaml-6.0 requests-2.27.1 sacremoses-0.0.47 segtok-1.5.11 sentencepiece-0.1.95 sqlitedict-1.7.0 tokenizers-0.10.3 transformers-4.15.0 wikipedia-api-0.5.4\n"]}],"source":["#install in anaconda cmd window run as administrator, then restart jupyter notebook\n","\n","!pip install flair"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RWiXNbY7KYaC","executionInfo":{"status":"ok","timestamp":1642003877851,"user_tz":-480,"elapsed":2581,"user":{"displayName":"Ëî°ÊâøÂì≤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUjUENY9knqXHiDlNA8p9rKPZb-kSJuB4r-BTpIQ=s64","userId":"08856972309667959252"}},"outputId":"bc0c841a-cae2-4326-bde9-2f26b674834e"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-01-12 16:11:15,088 loading file /root/.flair/models/sentiment-en-mix-distillbert_4.pt\n","Sentence above is:  [POSITIVE (0.9923)]\n","Sentence above is:  [NEGATIVE (0.9995)]\n"]}],"source":["#it will download the database may take a while (266M)\n","from flair.models import TextClassifier\n","from flair.data import Sentence\n","\n","classifier = TextClassifier.load('en-sentiment')\n","sentences = [\"I am very kind and good\",\n","             \"I am very angry\",\n","             ]\n","for sentence in sentences:\n","    s = Sentence(sentence)\n","    classifier.predict(s)\n","    print('Sentence above is: ', s.labels)"]},{"cell_type":"markdown","metadata":{"id":"ZcnwS0YqKYaC"},"source":["### Question\n","Create a common set of sentences (similar to the sentences in the VADER example) and use the 3 different libraries to extract the sentiments. Compare the results. \n","- Which library you think is better? \n","- What improvements do you think can be incorporated into the library to improve the classification? "]},{"cell_type":"markdown","source":["### Answer \n","I think vader is better, because it can Analyze the intensity of sentiment in the text"],"metadata":{"id":"3ksymOytTDAe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xe3TSFHiKYaD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641991316447,"user_tz":-480,"elapsed":10,"user":{"displayName":"Ëî°ÊâøÂì≤","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUjUENY9knqXHiDlNA8p9rKPZb-kSJuB4r-BTpIQ=s64","userId":"08856972309667959252"}},"outputId":"61bb5d73-69c2-446a-a16c-7321cbfeeb49"},"outputs":[{"output_type":"stream","name":"stdout","text":[" I was delighted at your promotion............................... {'neg': 0.0, 'neu': 0.602, 'pos': 0.398, 'compound': 0.5106}\n"," I‚Äôm pleased with my son‚Äôs grades this year...................... {'neg': 0.0, 'neu': 0.707, 'pos': 0.293, 'compound': 0.4404}\n"," His insult drives me mad! ...................................... {'neg': 0.694, 'neu': 0.306, 'pos': 0.0, 'compound': -0.7777}\n","He was annoyed by my indifference. .............................. {'neg': 0.487, 'neu': 0.513, 'pos': 0.0, 'compound': -0.4215}\n"," I was delighted at your promotion................ Sentiment(polarity=0.7, subjectivity=0.7)\n"," I‚Äôm pleased with my son‚Äôs grades this year....... Sentiment(polarity=0.5, subjectivity=1.0)\n"," His insult drives me mad! ....................... Sentiment(polarity=-0.78125, subjectivity=1.0)\n","He was annoyed by my indifference. ............... Sentiment(polarity=-0.4, subjectivity=0.8)\n","Sentence above is:  [POSITIVE (0.9945)]\n","Sentence above is:  [POSITIVE (0.9808)]\n","Sentence above is:  [NEGATIVE (0.9963)]\n","Sentence above is:  [NEGATIVE (0.999)]\n"]}],"source":["#Q1\n","sentences1 = [\" I was delighted at your promotion.\",\n","              ' I‚Äôm pleased with my son‚Äôs grades this year.',\n","             \" His insult drives me mad! \",\n","             'He was annoyed by my indifference. ',\n","              ]\n","\n","# vader\n","for sentence in sentences1:\n","    vs = analyzer.polarity_scores(sentence)\n","    print(\"{:.<65} {}\".format(sentence, str(vs)))\n","\n","# textblob\n","for sentence in sentences1:\n","    vs = TextBlob(sentence)\n","    print(\"{:.<50} {}\".format(sentence, str(vs.sentiment)))\n","\n","# flair\n","for sentence in sentences1:\n","    s = Sentence(sentence)\n","    classifier.predict(s)\n","    #print(\"{:.<65} {}\".format(sentence, vs.labels))\n","    print('Sentence above is: ', s.labels)"]},{"cell_type":"markdown","source":["### Answer \n","2.  \n","More data can be added. If a language that expresses emotions is commonly used, then the accuracy of the word can be increased in a large amount of data. For example, the word \"interesting\" was originally neutral, but was used as a derogatory meaning Much more, the model will automatically discover its negative connotations."],"metadata":{"id":"f1L-w-2MW0Yb"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"Sentiments.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}